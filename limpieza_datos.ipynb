{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 0: Carga de los datos desde la base SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Conexión a la base de datos\n",
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Cargar todas las tablas necesarias\n",
    "departments = pd.read_sql(\"SELECT * FROM departments\", conn)\n",
    "aisles = pd.read_sql(\"SELECT * FROM aisles\", conn)\n",
    "products = pd.read_sql(\"SELECT * FROM products\", conn)\n",
    "orders = pd.read_sql(\"SELECT * FROM orders\", conn)\n",
    "order_products_prior = pd.read_sql(\"SELECT * FROM order_products_prior\", conn)\n",
    "order_products_train = pd.read_sql(\"SELECT * FROM order_products_train\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 1: Exploración inicial de order_products_prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  product_id  add_to_cart_order  reordered\n",
      "0         2       33120                  1          1\n",
      "1         2       28985                  2          1\n",
      "2         2        9327                  3          0\n",
      "3         2       45918                  4          1\n",
      "4         2       30035                  5          0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32434489 entries, 0 to 32434488\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype\n",
      "---  ------             -----\n",
      " 0   order_id           int64\n",
      " 1   product_id         int64\n",
      " 2   add_to_cart_order  int64\n",
      " 3   reordered          int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 989.8 MB\n",
      "None\n",
      "           order_id    product_id  add_to_cart_order     reordered\n",
      "count  3.243449e+07  3.243449e+07       3.243449e+07  3.243449e+07\n",
      "mean   1.710749e+06  2.557634e+04       8.351076e+00  5.896975e-01\n",
      "std    9.873007e+05  1.409669e+04       7.126671e+00  4.918886e-01\n",
      "min    2.000000e+00  1.000000e+00       1.000000e+00  0.000000e+00\n",
      "25%    8.559430e+05  1.353000e+04       3.000000e+00  0.000000e+00\n",
      "50%    1.711048e+06  2.525600e+04       6.000000e+00  1.000000e+00\n",
      "75%    2.565514e+06  3.793500e+04       1.100000e+01  1.000000e+00\n",
      "max    3.421083e+06  4.968800e+04       1.450000e+02  1.000000e+00\n",
      "Duplicados: 0\n",
      "Valores únicos por columna:\n",
      "order_id             3214874\n",
      "product_id             49677\n",
      "add_to_cart_order        145\n",
      "reordered                  2\n",
      "dtype: int64\n",
      "Nulos por columna:\n",
      "order_id             0\n",
      "product_id           0\n",
      "add_to_cart_order    0\n",
      "reordered            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver los primeros registros\n",
    "print(order_products_prior.head())\n",
    "\n",
    "# Ver estructura general\n",
    "print(order_products_prior.info())\n",
    "\n",
    "# Ver estadísticos generales\n",
    "print(order_products_prior.describe())\n",
    "\n",
    "# Ver número de duplicados exactos\n",
    "print(\"Duplicados:\", order_products_prior.duplicated().sum())\n",
    "\n",
    "# Ver valores únicos por columna\n",
    "print(\"Valores únicos por columna:\")\n",
    "print(order_products_prior.nunique())\n",
    "\n",
    "# Verificar si hay nulos\n",
    "print(\"Nulos por columna:\")\n",
    "print(order_products_prior.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Coinciden los nulos con el primer pedido?: True\n"
     ]
    }
   ],
   "source": [
    "primeros_pedidos = orders[orders[\"order_number\"] == 1]\n",
    "print(\"¿Coinciden los nulos con el primer pedido?:\", primeros_pedidos[\"days_since_prior_order\"].isnull().all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 2: Unir order_products_prior con orders para obtener user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Nulos en user_id?: 0\n",
      "   order_id  product_id  add_to_cart_order  reordered  user_id\n",
      "0         2       33120                  1          1   202279\n",
      "1         2       28985                  2          1   202279\n",
      "2         2        9327                  3          0   202279\n",
      "3         2       45918                  4          1   202279\n",
      "4         2       30035                  5          0   202279\n"
     ]
    }
   ],
   "source": [
    "# Filtrar solo los pedidos previos\n",
    "orders_prior = orders[orders[\"eval_set\"] == \"prior\"][[\"order_id\", \"user_id\"]]\n",
    "\n",
    "# Unir para añadir user_id a order_products_prior\n",
    "order_prior_merged = order_products_prior.merge(orders_prior, on=\"order_id\", how=\"left\")\n",
    "\n",
    "# Verificamos que no haya nulos en user_id\n",
    "print(\"¿Nulos en user_id?:\", order_prior_merged[\"user_id\"].isnull().sum())\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "print(order_prior_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 3: Crear la matriz user_id × product_id con frecuencia de compra para el modelo SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  product_id  purchase_count\n",
      "0        1         196              10\n",
      "1        1       10258               9\n",
      "2        1       10326               1\n",
      "3        1       12427              10\n",
      "4        1       13032               3\n",
      "Shape: (13307953, 3)\n",
      "Nulos: user_id           0\n",
      "product_id        0\n",
      "purchase_count    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por user_id y product_id para contar cuántas veces ha comprado ese producto\n",
    "user_product_matrix = order_prior_merged.groupby([\"user_id\", \"product_id\"]).size().reset_index(name=\"purchase_count\")\n",
    "\n",
    "# Mostrar las primeras filas para comprobar\n",
    "print(user_product_matrix.head())\n",
    "\n",
    "# Comprobación básica\n",
    "print(\"Shape:\", user_product_matrix.shape)\n",
    "print(\"Nulos:\", user_product_matrix.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 4: Preparar los datos para el modelo SVD de Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    3.4489  3.4424  3.4482  3.4465  0.0029  \n",
      "MAE (testset)     1.7598  1.7578  1.7593  1.7590  0.0008  \n",
      "Fit time          78.47   79.35   78.99   78.94   0.36    \n",
      "Test time         25.69   24.58   25.81   25.36   0.55    \n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Crear un Reader indicando que los ratings van de 1 en adelante (frecuencia)\n",
    "reader = Reader(rating_scale=(1, user_product_matrix[\"purchase_count\"].max()))\n",
    "\n",
    "# Cargar los datos desde el dataframe\n",
    "data = Dataset.load_from_df(user_product_matrix[[\"user_id\", \"product_id\", \"purchase_count\"]], reader)\n",
    "\n",
    "# Definir modelo SVD\n",
    "model = SVD()\n",
    "\n",
    "# Evaluar con validación cruzada\n",
    "results = cross_validate(model, data, measures=[\"RMSE\", \"MAE\"], cv=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Paso 1: Crear dataset desde el dataframe\n",
    "reader = Reader(rating_scale=(1, user_product_matrix[\"purchase_count\"].max()))\n",
    "data = Dataset.load_from_df(user_product_matrix[[\"user_id\", \"product_id\", \"purchase_count\"]], reader)\n",
    "\n",
    "# Paso 2: Dividir en train y test\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Paso 3: Entrenar el modelo en el set de entrenamiento\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Paso 4: Hacer predicciones sobre el testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Paso 5: Obtener el top-N recomendado para cada usuario\n",
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    # Ordenar por score estimado descendente y quedarnos con top-N\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        top_n[uid] = sorted(user_ratings, key=lambda x: x[1], reverse=True)[:n]\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 1.0000\n",
      "Recall@10:    0.7890\n",
      "F1-Score@10:  0.8520\n"
     ]
    }
   ],
   "source": [
    "# Paso 6: Construir diccionarios para comparar\n",
    "# Lo que el usuario realmente compró en el testset\n",
    "actual = defaultdict(set)\n",
    "for uid, iid, true_r in testset:\n",
    "    if true_r >= 1:  # consideramos que fue \"relevante\" si se compró al menos una vez\n",
    "        actual[uid].add(iid)\n",
    "\n",
    "# Lo que el sistema recomendó\n",
    "recommended = {uid: set([iid for iid, _ in items]) for uid, items in top_n.items()}\n",
    "\n",
    "# Paso 7: Métricas agregadas\n",
    "precision_list, recall_list, f1_list = [], [], []\n",
    "\n",
    "for uid in actual:\n",
    "    if uid in recommended:\n",
    "        true_items = actual[uid]\n",
    "        rec_items = recommended[uid]\n",
    "        tp = len(true_items & rec_items)\n",
    "        fp = len(rec_items - true_items)\n",
    "        fn = len(true_items - rec_items)\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "# Resultado final\n",
    "print(f\"Precision@10: {np.mean(precision_list):.4f}\")\n",
    "print(f\"Recall@10:    {np.mean(recall_list):.4f}\")\n",
    "print(f\"F1-Score@10:  {np.mean(f1_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1  # puedes cambiarlo por cualquier otro que tengas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya ha comprado: 18 productos.\n"
     ]
    }
   ],
   "source": [
    "# Productos que ya compró el usuario (usando la tabla original mergeada)\n",
    "productos_comprados = order_prior_merged[order_prior_merged[\"user_id\"] == user_id][\"product_id\"].unique()\n",
    "print(\"Ya ha comprado:\", len(productos_comprados), \"productos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los product_id posibles\n",
    "todos_los_productos = products[\"product_id\"].unique()\n",
    "\n",
    "# Filtramos los que no ha comprado\n",
    "productos_no_comprados = np.setdiff1d(todos_los_productos, productos_comprados)\n",
    "\n",
    "# Creamos predicciones para esos productos\n",
    "predicciones = [model.predict(uid=user_id, iid=pid) for pid in productos_no_comprados]\n",
    "\n",
    "# Ordenamos por estimación descendente y cogemos los mejores N\n",
    "top_n_predicciones = sorted(predicciones, key=lambda x: x.est, reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recomendaciones para el usuario 1\n",
      "       product_id                                       product_name\n",
      "6947         6948                       Organic Original Almond Milk\n",
      "20297       20298                        Diet Green Tea with Ginseng\n",
      "22958       22959                 Reduced Fat Milk 100% Lactose Free\n",
      "35411       35412  Select Tender Chicken with Vegetables & Brown ...\n",
      "37709       37710                                          Trail Mix\n",
      "39862       39863                                    Organic 2% Milk\n",
      "42243       42244  Total 2% All Natural Low Fat 2% Milkfat Greek ...\n",
      "43393       43394                    Organic Lactose Free Whole Milk\n",
      "45327       45328                              Flavored Vodka, Peach\n",
      "48856       48857                           Authentic French Brioche\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los nombres de los productos recomendados\n",
    "recommended_product_ids = [pred.iid for pred in top_n_predicciones]\n",
    "\n",
    "# Filtramos de la tabla products\n",
    "productos_recomendados = products[products[\"product_id\"].isin(recommended_product_ids)]\n",
    "\n",
    "print(\"Top-10 recomendaciones para el usuario\", user_id)\n",
    "print(productos_recomendados[[\"product_id\", \"product_name\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_productos(user_id, model, products_df, order_prior_merged, top_n=10):\n",
    "    # Productos que ya ha comprado el usuario\n",
    "    productos_comprados = order_prior_merged[order_prior_merged[\"user_id\"] == user_id][\"product_id\"].unique()\n",
    "    todos_los_productos = products_df[\"product_id\"].unique()\n",
    "    productos_no_comprados = np.setdiff1d(todos_los_productos, productos_comprados)\n",
    "\n",
    "    # Predecir para los que no ha comprado\n",
    "    predicciones = [model.predict(uid=user_id, iid=pid) for pid in productos_no_comprados]\n",
    "    top_n_predicciones = sorted(predicciones, key=lambda x: x.est, reverse=True)[:top_n]\n",
    "    recommended_ids = [pred.iid for pred in top_n_predicciones]\n",
    "\n",
    "    # Mostrar nombres\n",
    "    return products_df[products_df[\"product_id\"].isin(recommended_ids)][[\"product_id\", \"product_name\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6947</th>\n",
       "      <td>6948</td>\n",
       "      <td>Organic Original Almond Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20297</th>\n",
       "      <td>20298</td>\n",
       "      <td>Diet Green Tea with Ginseng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>22959</td>\n",
       "      <td>Reduced Fat Milk 100% Lactose Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35411</th>\n",
       "      <td>35412</td>\n",
       "      <td>Select Tender Chicken with Vegetables &amp; Brown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37709</th>\n",
       "      <td>37710</td>\n",
       "      <td>Trail Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39862</th>\n",
       "      <td>39863</td>\n",
       "      <td>Organic 2% Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42243</th>\n",
       "      <td>42244</td>\n",
       "      <td>Total 2% All Natural Low Fat 2% Milkfat Greek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43393</th>\n",
       "      <td>43394</td>\n",
       "      <td>Organic Lactose Free Whole Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45327</th>\n",
       "      <td>45328</td>\n",
       "      <td>Flavored Vodka, Peach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48856</th>\n",
       "      <td>48857</td>\n",
       "      <td>Authentic French Brioche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                                       product_name\n",
       "6947         6948                       Organic Original Almond Milk\n",
       "20297       20298                        Diet Green Tea with Ginseng\n",
       "22958       22959                 Reduced Fat Milk 100% Lactose Free\n",
       "35411       35412  Select Tender Chicken with Vegetables & Brown ...\n",
       "37709       37710                                          Trail Mix\n",
       "39862       39863                                    Organic 2% Milk\n",
       "42243       42244  Total 2% All Natural Low Fat 2% Milkfat Greek ...\n",
       "43393       43394                    Organic Lactose Free Whole Milk\n",
       "45327       45328                              Flavored Vodka, Peach\n",
       "48856       48857                           Authentic French Brioche"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendar_productos(1, model, products, order_prior_merged, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product_id                             product_name\n",
      "43       38928                 0% Greek Strained Yogurt\n",
      "33       26088               Aged White Cheddar Popcorn\n",
      "7        13176                   Bag of Organic Bananas\n",
      "6        41787                           Bartlett Pears\n",
      "17       13032                    Cinnamon Toast Crunch\n",
      "12       30450                     Creamy Almond Butter\n",
      "5        17122                        Honeycrisp Apples\n",
      "42       39657                   Milk Chocolate Almonds\n",
      "4        10326                      Organic Fuji Apples\n",
      "23       49235                      Organic Half & Half\n",
      "3        25133                    Organic String Cheese\n",
      "46       35951          Organic Unsweetened Almond Milk\n",
      "36       14084  Organic Unsweetened Vanilla Almond Milk\n",
      "1        12427                      Original Beef Jerky\n",
      "2        10258                               Pistachios\n",
      "0          196                                     Soda\n",
      "22       26405         XL Pick-A-Size Paper Towel Rolls\n",
      "24       46149                        Zero Calorie Cola\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los productos comprados por el usuario 1\n",
    "compras_usuario = order_prior_merged[order_prior_merged[\"user_id\"] == 1]\n",
    "\n",
    "# Unir con products para ver los nombres\n",
    "compras_usuario = compras_usuario.merge(products, on=\"product_id\", how=\"left\")\n",
    "\n",
    "# Ver productos únicos que ha comprado\n",
    "productos_comprados = compras_usuario[[\"product_id\", \"product_name\"]].drop_duplicates().sort_values(\"product_name\")\n",
    "\n",
    "print(productos_comprados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svd_model_good_precision.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"svd_model_good_precision.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MBA (MARKET BASKET ANALYSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Filtrar productos frecuentes y muestrear pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtrar productos que aparezcan más de 500 veces\n",
    "frequent_products = order_products_prior[\"product_id\"].value_counts()\n",
    "popular_products = frequent_products[frequent_products > 500].index\n",
    "\n",
    "# 2. Filtrar el dataframe original\n",
    "filtered_op_prior = order_products_prior[order_products_prior[\"product_id\"].isin(popular_products)]\n",
    "\n",
    "# 3. Tomar una muestra de pedidos (por ejemplo, 100.000 pedidos distintos)\n",
    "sampled_order_ids = filtered_op_prior[\"order_id\"].drop_duplicates().sample(n=100_000, random_state=42)\n",
    "\n",
    "# 4. Crear la lista de transacciones (listas de productos por pedido)\n",
    "basket = filtered_op_prior[filtered_op_prior[\"order_id\"].isin(sampled_order_ids)] \\\n",
    "    .groupby(\"order_id\")[\"product_id\"].apply(list)\n",
    "\n",
    "transactions = basket.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Convertir a formato one-hot (sparse para ahorrar RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7667/3804387274.py:9: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df_transactions = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Codificación one-hot (ahorro de memoria usando sparse=True)\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions, sparse=True)\n",
    "\n",
    "# Convertir a dataframe sparse\n",
    "import pandas as pd\n",
    "df_transactions = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Aplicar Apriori para encontrar itemsets frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support itemsets\n",
      "42  0.15059  (24852)\n",
      "21  0.11865  (13176)\n",
      "31  0.08287  (21137)\n",
      "34  0.07512  (21903)\n",
      "96  0.06697  (47209)\n",
      "98  0.05497  (47766)\n",
      "97  0.04720  (47626)\n",
      "45  0.04472  (26209)\n",
      "52  0.04458  (27845)\n",
      "24  0.04451  (16797)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Convertir nombres de columnas a string (requerido por mlxtend con sparse)\n",
    "df_transactions.columns = df_transactions.columns.astype(str)\n",
    "\n",
    "# Extraer itemsets frecuentes con soporte mínimo (ajustable)\n",
    "frequent_itemsets = apriori(df_transactions, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Mostrar los más frecuentes\n",
    "print(frequent_itemsets.sort_values(\"support\", ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Generar reglas de asociación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  support  confidence      lift\n",
      "0     (28204)     (24852)  0.01009    0.375372  2.492676\n",
      "1     (47766)     (24852)  0.01653    0.300709  1.996875\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Crear reglas con confianza mínima del 30%\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.3)\n",
    "\n",
    "# Ordenar por lift (las más interesantes)\n",
    "rules = rules.sort_values(\"lift\", ascending=False)\n",
    "\n",
    "# Ver las mejores 10 reglas\n",
    "print(rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [product_id, product_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Convertimos las reglas a un formato fácil de consultar\n",
    "# Por cada antecedente, nos quedamos con el consecuente más fuerte\n",
    "top_rules = rules.sort_values(\"lift\", ascending=False).drop_duplicates(subset=\"antecedents\")\n",
    "\n",
    "# Creamos un diccionario: antecedente → consecuente\n",
    "reglas_dict = {tuple(ant): list(cons)[0] for ant, cons in zip(top_rules[\"antecedents\"], top_rules[\"consequents\"])}\n",
    "\n",
    "# Función para recomendar productos en base a lo que ha comprado un usuario\n",
    "def recomendar_mba(user_id, ordenes_df, reglas_dict):\n",
    "    productos_usuario = ordenes_df[ordenes_df[\"user_id\"] == user_id][\"product_id\"].unique()\n",
    "    recomendaciones = set()\n",
    "    for producto in productos_usuario:\n",
    "        if (producto,) in reglas_dict:\n",
    "            recomendaciones.add(reglas_dict[(producto,)])\n",
    "    return list(recomendaciones)\n",
    "\n",
    "# Ejemplo: recomendaciones MBA para el usuario 1\n",
    "recomendaciones_mba = recomendar_mba(1, order_prior_merged, reglas_dict)\n",
    "\n",
    "# Mostrar con nombres\n",
    "productos_mba = products[products[\"product_id\"].isin(recomendaciones_mba)]\n",
    "print(productos_mba[[\"product_id\", \"product_name\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
